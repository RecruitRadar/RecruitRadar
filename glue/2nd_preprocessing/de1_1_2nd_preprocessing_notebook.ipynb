{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### This is a Glue Studio notebook for performing second-round preprocessing\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "### install kiwipiepy library",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%additional_python_modules kiwipiepy==0.15.2",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.38.1 \nAdditional python modules to be included:\nkiwipiepy==0.15.2\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "###  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 20\n\n# library for setting glue studio notebook\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\n# library for conducting 2nd preprocessing\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import ArrayType, StringType\nfrom botocore.exceptions import NoCredentialsError\nfrom botocore.exceptions import ClientError\nfrom datetime import date\nfrom kiwipiepy import Kiwi\nimport boto3\nimport json\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session fd37e023-017b-4f51-9b74-856950035af2.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is 2800 minutes.\nidle_timeout has been set to 2880 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session fd37e023-017b-4f51-9b74-856950035af2.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 3.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session fd37e023-017b-4f51-9b74-856950035af2.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous worker type: G.1X\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session fd37e023-017b-4f51-9b74-856950035af2.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous number of workers: 5\nSetting new number of workers to: 5\nModuleNotFoundError: No module named 'kiwipiepy'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### setting S3 uploader class",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "class S3Uploader:\n    def __init__(self, bucket_name, access_key, secret_key, region_name):\n        self.bucket_name = bucket_name\n        self.access_key = access_key\n        self.secret_key = secret_key\n        self.s3 = boto3.client(\n            's3',\n            aws_access_key_id=access_key,\n            aws_secret_access_key=secret_key,\n            region_name=region_name\n        )\n\n    def get_upload_file_path(self):\n        \"\"\"\n        1차 전처리된 최종 parquet 파일을 s3에 업로드할 경로를 리턴합니다.\n        \"\"\"\n        today = date.today()\n        year = str(today.year)\n        month = str(today.month).zfill(2)\n        day = str(today.day).zfill(2)\n\n        return f's3://{self.bucket_name}/2nd_processed_data/year={year}/month={month}/day={day}'",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def get_secret():\n    \"\"\"\n    AWS Secrets Manager를 이용해 환경변수를 불러옵니다.\n    \"\"\"\n    secret_name = \"prod/de-1-1/back-end\"\n    REGION_NAME = \"ap-northeast-2\"\n\n    session = boto3.session.Session()\n    client = session.client(\n        service_name='secretsmanager',\n        region_name=REGION_NAME\n    )\n\n    try:\n        get_secret_value_response = client.get_secret_value(\n            SecretId=secret_name\n        )\n    except ClientError as e:\n        raise e\n\n    secret = get_secret_value_response['SecretString']\n    secret_dict = json.loads(secret)\n\n    BUCKET_NAME = secret_dict['BUCKET_NAME']\n    ACCESS_KEY = secret_dict['AWS_ACCESS_KEY_ID']\n    SECRET_KEY = secret_dict['AWS_SECRET_ACCESS_KEY']\n    KAKAO_API_TOKEN = secret_dict['KAKAO_API_TOKEN']\n\n    return BUCKET_NAME, ACCESS_KEY, SECRET_KEY, REGION_NAME, KAKAO_API_TOKEN",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "dyf = glueContext.create_dynamic_frame.from_catalog(database='de1_1_database', table_name='de1_1_1st_cleaned_data')\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- job_id: long\n|-- platform: string\n|-- category: string\n|-- company: string\n|-- title: string\n|-- preferred: string\n|-- required: string\n|-- primary_responsibility: string\n|-- url: string\n|-- end_at: string\n|-- skills: array\n|    |-- element: string\n|-- location: string\n|-- welfare: string\n|-- body: int\n|-- company_description: string\n|-- coordinate: int\n|-- year: string\n|-- month: string\n|-- day: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "df = dyf.toDF()\ndf.show()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.38.1 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::862327261051:role/DE1_1_Glue_Role\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: fd37e023-017b-4f51-9b74-856950035af2\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.38.1\n--enable-glue-datacatalog true\nWaiting for session fd37e023-017b-4f51-9b74-856950035af2 to get into ready status...\nSession fd37e023-017b-4f51-9b74-856950035af2 has been created.\nNameError: name 'dyf' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Drop Columns year, month, day",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "drop_cols = (\"year\", \"month\", \"day\")\ndf = df.drop(*drop_cols)\ndf.printSchema()\ndf.show()",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "### Fucntions for extracting nouns",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "@udf(returnType=ArrayType(StringType()))\ndef extract_korean_noun(text):\n    if text is None or text.strip() == \"\":\n        return []\n    kiwi = Kiwi()\n    result = kiwi.tokenize(text)\n    return [token.form for token in result if token.tag in {'NNG', 'NNP'}]",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "NameError: name 'udf' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "@udf(returnType=ArrayType(StringType()))\ndef extract_english_noun(text):\n    if text is None or text.strip() == \"\":\n        return []\n    kiwi = Kiwi()\n    result = kiwi.tokenize(text)\n    return [token.form for token in result if token.tag == 'SL']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "NameError: name 'udf' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df = df.withColumn(\"preferred_korean_nouns\", extract_korean_noun(df[\"preferred\"]))\ndf = df.withColumn(\"required_korean_nouns\", extract_korean_noun(df[\"required\"]))\ndf = df.withColumn(\"primary_responsibility_korean_nouns\", extract_korean_noun(df[\"primary_responsibility\"]))\ndf = df.withColumn(\"welfare_korean_nouns\", extract_korean_noun(df[\"welfare\"]))\ndf = df.withColumn(\"preferred_english_nouns\", extract_english_noun(df[\"preferred\"]))\ndf = df.withColumn(\"required_english_nouns\", extract_english_noun(df[\"required\"]))\ndf = df.withColumn(\"primary_responsibility_english_nouns\", extract_english_noun(df[\"primary_responsibility\"]))\ndf = df.withColumn(\"welfare_english_nouns\", extract_english_noun(df[\"welfare\"]))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "NameError: name 'df' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.show()",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "repartitioned_df = df.repartition(1)",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "BUCKET_NAME, ACCESS_KEY, SECRET_KEY, REGION_NAME, _ = get_secret()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "NameError: name 'boto3' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "uploader = S3Uploader(BUCKET_NAME, ACCESS_KEY, SECRET_KEY, REGION_NAME)\nupload_file_path = uploader.get_upload_file_path()\nrepartitioned_df.write.parquet(upload_file_path, mode=\"overwrite\")",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "job.commit()\nsc.stop()",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}